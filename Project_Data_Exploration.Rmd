---
title: "GroupProject"
author: "Ruttansh Bhatelia, Xiaohong Deng"
date: "2024-02-06"
output: html_document
---

# Project: Tesla Stock Analysis-Insights from Historical Data Analysis

## Section1: Data Exploration:

### 1- Introduction

using the metadata and references from the literature. - This introduction should also include the rationale behind choosing this data set and topic. - You might want to research the topic before using the dataset. - Please use peer-reviewed sources as references (journal articles, books, government websites, etc.)

**Solution:**

Tesla, Inc., founded by Elon Musk and his partners, has experienced remarkable growth in market value, making its stock a focal point in investment circles. As stockholders, we are keen on delving into the intricacies of Tesla's stock performance and understanding the factors shaping its market behavior. The dataset, sourced from kaggle, encompasses Tesla's stock prices from its initial public offering (IPO) to August 15, 2023. It comprises essential parameters such as date, open, high, low, close, volume, adjusted_close, change_percent, and avg_vol_20d, providing a comprehensive perspective on Tesla's stock performance over time. This project will analyze the Tesla stock dataset across five phases: Data Exploration, Hypothesis Testing, Deriving Insights, Discussion and Conclusion, and Presentation.

### 2- Data summarization:

provide descriptive statistics of your data like mean, median, mode, quartiles, IQR, data types, etc., and interpret the output.

**Solution:**

```{r}
#load dataset from the csv file
tesla <- read.csv("tsla_raw_data.csv")
df <- data.frame(tesla)

#check dateframe quickly
head(df)
```

**Observation:**

-   The dataset contains several columns including 'open', 'high', 'low', 'close', 'volume', 'adjusted_close', 'change_percent', and 'avg_vol_20d'. These columns represent different aspects of Tesla stock data such as opening price, closing price, trading volume, etc.

-   The table reveals that the values across these columns fluctuate over time, as indicated by the 'date' column.

```{r}
#generate descriptive statistics including mean, median, mode, quartiles, IQR, data type, etc. using summary function
summary(df)
```

**Observation:**

-   The dataset contains 3305 entries, each representing a specific date, with a total of 9 columns. The "date" column is of character type, indicating dates, while the other columns, including "open," "high," "low," "close," "volume," "adjusted_close," "change_percent," and "avg_vol_20d," are numerical.

-   For numerical columns such as "open," "high," "low," "close," "volume," "adjusted_close," "change_percent," and "avg_vol_20d," descriptive statistics like minimum, maximum, quartiles (1st, 2nd, and 3rd), and mean are provided. However, for the character column "date," descriptive statistics include length, class, and mode.

-   There are some missing values in the "change_percent" and "avg_vol_20d" columns, as indicated by the NA values. These missing values will need to be handled appropriately in subsequent analyses.

### 3- Data visualization:

Use tables and graphs to organize, visualize, and explore your dataset.

**Solution:**

#### 3.1) using time series plots

to visualize how variables change over time. This can help identify trends, seasonality, and anomalies in the dataset.

```{r}
library(ggplot2)
library(plotly)

#convert 'date' column to Date format
df$date <- as.Date(df$date)

# Create time series plots for open, high, low, and close
g <- ggplot(df, aes(x = date)) +
  geom_line(aes(y = open, color = "Open")) +
  geom_line(aes(y = high, color = "High")) +
  geom_line(aes(y = low, color = "Low")) +
  geom_line(aes(y = close, color = "Close")) +
  labs(title = "Time Series Plot of Tesla Stock Prices",
       x = "Date",
       y = "Price",
       color = "Variables") +
  scale_color_manual(values = c("Open" = "blue", "High" = "red", "Low" = "green", "Close" = "orange")) 

ggplotly(g)
```

**Observation:**

-   Tesla Prices dropped suddenly on 2020/08/31 and 2022/08/25 because of stock splits(5-for-1 and 3-for-1, respectively). These splits made each existing share into multiple shares, causing the price per share to decrease. For example, if you had one TSLA share before August 31st, 2020, you'd now have 3*5=15 shares.

-   To keep the historical stock data accurate and avoid distortions from stock splits, the original dataset "tsla_raw_data" would be adjusted to ensure a clearer picture of Tesla's stock performance over time.

Adjust the the original dataset "tsla_raw_data" as follows

```{r}
# Create a dataFrame to save the old dataset
df_old <- df

# Convert the "date" column to Date format
df$date <- as.Date(df$date)

# Apply transformations based on date conditions
df[df$date < as.Date("2020-08-31"), c("open", "high", "low", "close")] <- 
  df[df$date < as.Date("2020-08-31"), c("open", "high", "low", "close")] / 15

df[df$date < as.Date("2020-08-31"), c("volume", "adjusted_close")] <- 
  df[df$date < as.Date("2020-08-31"), c("volume", "adjusted_close")] * 15

df[df$date >= as.Date("2020-08-31") & df$date < as.Date("2022-08-25"), c("open", "high", "low", "close")] <- 
  df[df$date >= as.Date("2020-08-31") & df$date < as.Date("2022-08-25"), c("open", "high", "low", "close")] / 3

df[df$date >= as.Date("2020-08-31") & df$date < as.Date("2022-08-25"), c("volume", "adjusted_close")] <- 
  df[df$date >= as.Date("2020-08-31") & df$date < as.Date("2022-08-25"), c("volume", "adjusted_close")] * 3

# Display the transformed dataframe
head(df)
```

```{r}
#convert 'date' column to Date format
df$date <- as.Date(df$date)

# Create time series plots for open, high, low, and close over date
g2<-ggplot(df, aes(x = date)) +
  geom_line(aes(y = open, color = "Open")) +
  geom_line(aes(y = high, color = "High")) +
  geom_line(aes(y = low, color = "Low")) +
  geom_line(aes(y = close, color = "Close")) +
  labs(title = "Time Series Plot of Tesla Stock Prices",
       x = "Date",
       y = "Price",
       color = "Variables") +
  scale_color_manual(values = c("Open" = "blue", "High" = "red", "Low" = "green", "Close" = "orange"))

ggplotly(g2)

```

**Observation:**

-   The time series plots above provide a clear visualization of how the variables "open," "high," "low," and "close" change over time. These plots are valuable for identifying trends, patterns, seasonality, and any unusual fluctuations in Tesla's stock prices dataset.

```{r}
# Create time series plot for volume over time
ggplot(df, aes(x = date, y = volume)) +
  geom_line(color = "blue") +
  labs(title = "Time Series Plot of Tesla Trading Volume",
       x = "Date",
       y = "Volume")
```

**Observation:**

-   The plots above depict fluctuations in trading volume over time, with peaks often aligning with notable events or news releases that influence investor behavior and market activity.

```{r}
# Create a time series plot for 'change_percent' over time('date')
ggplot(df, aes(x = date, y = change_percent)) +
  geom_line() +
  labs(title = "Time Series Plot of Change Percent",
       x = "Date",
       y = "Change Percent")
```

**Observation:**

-   The plot displays the daily percentage change of Tesla's stock price, highlighting the volatility over the observed period. Sharp spikes and dips depict significant price movements, possibly influenced by news events, earnings reports, or broader economic conditions.

-   The warning message indicates the presence of null values in the 'change_percent' column, which should be addressed during data preparation before proceeding with further analysis.

#### 3.2) using a quantile-quantile plot

to verify normality for each column. If the qqplot is linear, then we can assume normality.

```{r}
# Loop through each column in the dataframe and create Q-Q plot
for (col in names(df)) {
  if (is.numeric(df[[col]])) {
    # Create a Q-Q plot for the current column with column name as label
    qqnorm(df[[col]], main = paste("Q-Q Plot for", col))
  }
}
```

**Observation:**

-   The plot of the Q-Q plot for the 'change_percent' column appears to follow a linear pattern, suggesting that the data distribution may approximate normality.

#### 3.3) using corrplot

to explore the linear relationships between each pair of variables in the tesla dataset. This can help identify patterns, correlations, or trends within the datasets.

```{r}
#remove date column as it's not needed for correlation analysis
df_no_date <- df[,-1]

#calculate correlation matrix showing the correlation between each pair of variables
corr_mat <- round(cor(df_no_date),2)
corr_mat
```

```{r}
#using corrplot to show the correlation between each pair of variables
install.packages("corrplot")
library(corrplot)
corrplot(corr_mat, method="square")
```

**Observation:**

-   The ? message indicates the presence of null values in the 'change_percent' column and the 'avg_vol_20d' column, which should be addressed during data preparation before proceeding with further analysis.

-   The splot indicates that there is strong positive linear relationship between each pairs of "open," "high," "low," and "close".

-   A moderate positive linear relationship is observed between 'volume' and 'avg_vol_20d'.

-   There exists a moderate positive linear relationship between 'raw_close' and each price variable ("open," "high," "low," or "close").

-   For other variable pairs, the linear relationship is weak or nearly zero.

### 4- Data summarization:

Data quality: based on the values and visualizations, discuss the quality of your dataset and discuss how issues with data quality might impact your analysis (for example, if one of your graphs in (3) shows many extreme values, how does that impact the values you calculated in (2)). The provided metadata can help you with evaluating the quality of your data. In addition, please take the necessary steps to clean your data and prepare it for analysis (steps 2 and 3 can help you identify the steps needed to clean the dataset).

**Solution:**

#### 4.1) Missing data

Based on the results of the head and summary functions, we can see that there are some missing values in the "change_percent" and "avg_vol_20d" columns, as indicated by the NA values. These missing values can impact the accuracy of our analysis, particularly when calculating summary statistics or visualizing trends over time. To address this issue, we can either remove these rows or perform imputation. Given that these missing values occur in the first few rows and constitute a very small portion compared to the overall volume of this dataset, we will opt to remove these rows.

```{r}
# #We opted for the removal solution over imputation as it appears to be more reasonable.

# #calculate the mean of the 'change_percent' column
# mean_change_percent <- mean(df$change_percent, na.rm = TRUE)
# 
# #fill missing values in the 'change_percent' column with the mean
# df$change_percent[is.na(df$change_percent)] <- mean_change_percent
# 
# #calculate the mean of the 'avg_vol_20d' column
# mean_avg_vol_20d <- mean(df$avg_vol_20d, na.rm = TRUE)
# 
# #fill missing values in the 'avg_vol_20d' column with the mean
# df$avg_vol_20d[is.na(df$avg_vol_20d)] <- mean_avg_vol_20d
# 
# #quickly check the result
# head(df)

```
```{r}
#We opted for the removal solution over imputation as it appears to be more reasonable.

# Remove rows with NA values in 'change_percent' or 'avg_vol_20d' columns
df <- df[complete.cases(df[c("change_percent", "avg_vol_20d")]), ]

# Quick check of the resulting dataframe
head(df)

```



```{r}
#remove date column as it's not needed for correlation analysis
df_no_date <- df[,-1]

#calculate correlation matrix showing the correlation between each pair of variables
corr_mat <- round(cor(df_no_date),2)
corr_mat

#using corrplot to show the correlation between each pair of variables
install.packages("corrplot")
library(corrplot)
corrplot(corr_mat, method="square")
```
**Observation:**

-   The splot indicates that there is strong positive linear relationship between each pairs of "open," "high," "low," and "close".

-   A moderate positive linear relationship is observed between 'volume' and 'avg_vol_20d'.

-   There exists a moderate positive linear relationship between 'raw_close' and each price variable ("open," "high," "low," or "close").

-   For other variable pairs, the linear relationship is weak or nearly zero.

#### 4.2) Inconsistency data

During data visualization, inconsistencies were observed before/after 2020/08/31 and 2022/08/25 due to stock splits. These splits caused Tesla's prices to drop suddenly on those dates. To ensure the historical accuracy of the stock data and avoid distortions from stock splits, the original dataset "tsla_raw_data" was adjusted. This adjustment led to the creation of a new dataset called "tsla_split_adjusted," providing a clearer and more accurate depiction of Tesla's stock performance over time.

```{r}
head(df_old)
```

```{r}
head(df)
```
```{r}
#export the updated tesla dataset as tesla_updated.csv file
write.csv(df, file = "tesla_updated.csv", row.names = FALSE)
```


